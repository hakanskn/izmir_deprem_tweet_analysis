{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "izmir_deprem_twitter_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca4tPI8bYjp2"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from datetime import datetime\r\n",
        "import os\r\n",
        "import time\r\n",
        "!pip install ipython-autotime\r\n",
        "%load_ext autotime\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from wordcloud import WordCloud, STOPWORDS\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stopWords_tr = set(stopwords.words('turkish'))\r\n",
        "!pip install tweet-preprocessor\r\n",
        "import string\r\n",
        "import re\r\n",
        "\r\n",
        "!pip install vaderSentiment\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4LbhTE9aXVp"
      },
      "source": [
        "df = pd.read_csv('twitter_data.csv')\r\n",
        "\r\n",
        "print(\"başlangıç veri seti satır sayısı\", df.shape)\r\n",
        "\r\n",
        "df = df.drop_duplicates(subset=['Tweet Id'])\r\n",
        "df.dropna(axis=0, how='any', subset=['Text', 'Tweet Id'], inplace=True)\r\n",
        "df['Datetime'] = df['Datetime'].str.replace('\\+00:00', '')\r\n",
        "\r\n",
        "df['clean_text'] =  df['Text'].apply(lambda x: re.sub(r\"(?:\\@|#|https?\\://)\\S+\", \"\", x).strip())\r\n",
        "\r\n",
        "df = df.replace('', np.nan, regex=True)\r\n",
        "df.dropna(axis=0, how='all', subset=['clean_text'], inplace=True)\r\n",
        "\r\n",
        "def remove_punc(test_str):\r\n",
        "  punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\r\n",
        "  for ele in test_str:  \r\n",
        "      if ele in punc:  \r\n",
        "          test_str = test_str.replace(ele, \"\")\r\n",
        "  return test_str\r\n",
        "\r\n",
        "\r\n",
        "df['clean_text'] =  df['clean_text'].apply(lambda x: remove_punc(x))\r\n",
        "\r\n",
        "def remove_stopwords(text):\r\n",
        "  from nltk.corpus import stopwords  \r\n",
        "  from nltk.tokenize import word_tokenize  \r\n",
        "    \r\n",
        "  word_tokens = word_tokenize(text)  \r\n",
        "  filtered_sentence = [w for w in word_tokens if not w in stopWords_tr]  \r\n",
        "  filtered_sentence = []  \r\n",
        "    \r\n",
        "  for w in word_tokens:  \r\n",
        "      if w not in stopWords_tr:  \r\n",
        "          filtered_sentence.append(w)  \r\n",
        "    \r\n",
        "  return ' '.join(filtered_sentence)\r\n",
        "\r\n",
        "\r\n",
        "df['clean_text'] =  df['clean_text'].apply(lambda x: remove_stopwords(x))\r\n",
        "\r\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0pHHsicrrrD"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUGyWfZQwhfi"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NP4qwDpecWx"
      },
      "source": [
        "df_grouped_by_tag = df.groupby(by=[\"hashtag\"], as_index=False).count()\r\n",
        "df_grouped_by_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeEkS1k_gOlw"
      },
      "source": [
        "plt.figure(figsize=(12,8))\r\n",
        "plt.bar(x=df_grouped_by_tag['hashtag'], height=df_grouped_by_tag['Tweet Id'])\r\n",
        "plt.xlabel('Etiket')\r\n",
        "plt.ylabel('Sayı')\r\n",
        "plt.title('Kullanılan Etiket sayısı')\r\n",
        "plt.xticks(rotation='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpazQ3XyTN2S"
      },
      "source": [
        "df_grouped_by_tag.set_index(df_grouped_by_tag['hashtag'], inplace=True)\r\n",
        "\r\n",
        "plott = df_grouped_by_tag.plot.pie(y='clean_text', figsize=(10, 10))\r\n",
        "\r\n",
        "plott.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swhyM-1q0R8a"
      },
      "source": [
        "\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "df['Datetime'] = pd.to_datetime(df['Datetime'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqKZYjFpmoYj"
      },
      "source": [
        "all_text = df['clean_text'].values\r\n",
        "wc2 = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='viridis', collocations=False, stopwords = stopWords_tr).generate(text=str(all_text))\r\n",
        "plt.figure(figsize=(12, 8))\r\n",
        "plt.imshow(wc2)\r\n",
        "plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLGO6LgXrGNC"
      },
      "source": [
        "df['mentions'] =  df['Text'].apply(lambda x: re.findall('\\s([@][\\w_-]+)', str(x)))\r\n",
        "df['hashtags'] =  df['Text'].apply(lambda x: re.findall('\\s([#][\\w_-]+)', str(x)))\r\n",
        "df['urls'] =  df['Text'].apply(lambda x: re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', str(x)))\r\n",
        "\r\n",
        "df['mention_count'] =  df['Text'].apply(lambda x: len(re.findall('\\s([@][\\w_-]+)', str(x))))\r\n",
        "df['hashtag_count'] =  df['Text'].apply(lambda x: len(re.findall('\\s([#][\\w_-]+)', str(x))))\r\n",
        "df['url_count'] =  df['Text'].apply(lambda x: len(re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', str(x))))\r\n",
        "\r\n",
        "df['dirty_text_word_count'] = df['Text'].apply(lambda x: len(str(x).split()))\r\n",
        "df['clean_text_word_count'] = df['clean_text'].apply(lambda x: len(str(x).split()))\r\n",
        "df['unique_word_count'] = df['clean_text'].apply(lambda x: len(set(str(x).split())))\r\n",
        "df['stop_word_count'] = df['clean_text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stopWords_tr]))\r\n",
        "#df['url_count'] = df['Text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\r\n",
        "df['mean_word_length'] = df['clean_text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\r\n",
        "df['dirty_text_char_count'] = df['Text'].apply(lambda x: len(str(x)))\r\n",
        "df['clean_text_char_count'] = df['clean_text'].apply(lambda x: len(str(x)))\r\n",
        "df['punctuation_count'] = df['clean_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\r\n",
        "df['difference_in_words'] = df['dirty_text_word_count'] - df['clean_text_word_count']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvUxUu83v1kZ"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "def generate_ngrams(text, n_gram=1):\r\n",
        "    token = [token for token in text.lower().split(' ') if token != '' if token not in stopWords_tr]\r\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\r\n",
        "    return [' '.join(ngram) for ngram in ngrams]\r\n",
        "\r\n",
        "N = 10\r\n",
        "\r\n",
        "# Unigrams\r\n",
        "unigrams = defaultdict(int)\r\n",
        "\r\n",
        "for tweet in df['clean_text']:\r\n",
        "    for word in generate_ngrams(tweet):\r\n",
        "        unigrams[word] += 1\r\n",
        "        \r\n",
        "df_unigrams = pd.DataFrame(sorted(unigrams.items(), key=lambda x: x[1])[::-1])\r\n",
        "\r\n",
        "# Bigrams\r\n",
        "bigrams = defaultdict(int)\r\n",
        "\r\n",
        "for tweet in df['clean_text']:\r\n",
        "    for word in generate_ngrams(tweet, n_gram=2):\r\n",
        "        bigrams[word] += 1\r\n",
        "        \r\n",
        "df_bigrams = pd.DataFrame(sorted(bigrams.items(), key=lambda x: x[1])[::-1])\r\n",
        "\r\n",
        "# Trigrams\r\n",
        "trigrams = defaultdict(int)\r\n",
        "\r\n",
        "for tweet in df['clean_text']:\r\n",
        "    for word in generate_ngrams(tweet, n_gram=3):\r\n",
        "        trigrams[word] += 1\r\n",
        "        \r\n",
        "df_trigrams = pd.DataFrame(sorted(trigrams.items(), key=lambda x: x[1])[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VarFR2c9HnD"
      },
      "source": [
        "import seaborn as sns\r\n",
        "\r\n",
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "sns.barplot(y=df_unigrams[0].values[:N], x=df_unigrams[1].values[:N], color='red')\r\n",
        "\r\n",
        "for i in range(1):\r\n",
        "    axes.set_xlabel('')\r\n",
        "    axes.set_ylabel('')\r\n",
        "    axes.tick_params(axis='x', labelsize=15)\r\n",
        "    axes.tick_params(axis='y', labelsize=15)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5Mp1__P7fi"
      },
      "source": [
        "df_unigrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9V56Xxj_kJ-"
      },
      "source": [
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "sns.barplot(y=df_bigrams[0].values[:N], x=df_bigrams[1].values[:N], color='red')\r\n",
        "\r\n",
        "for i in range(1):\r\n",
        "    axes.set_xlabel('')\r\n",
        "    axes.set_ylabel('')\r\n",
        "    axes.tick_params(axis='x', labelsize=15)\r\n",
        "    axes.tick_params(axis='y', labelsize=15)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bft2GtR7AInC"
      },
      "source": [
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "sns.barplot(y=df_trigrams[0].values[:N], x=df_trigrams[1].values[:N], color='red')\r\n",
        "\r\n",
        "for i in range(1):\r\n",
        "    axes.set_xlabel('')\r\n",
        "    axes.set_ylabel('')\r\n",
        "    axes.tick_params(axis='x', labelsize=15)\r\n",
        "    axes.tick_params(axis='y', labelsize=15)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSUlz1X2Cc7D"
      },
      "source": [
        "df_groupby_username = df.groupby(by=[\"Username\"], as_index=False).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8M7qwLDD5xH"
      },
      "source": [
        "df_groupby_username2 = df_groupby_username.sort_values(by='Tweet Id', ascending=False).head(10)\r\n",
        "\r\n",
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "sns.barplot(y=df_groupby_username2['Username'], x=df_groupby_username2['Tweet Id'])\r\n",
        "\r\n",
        "axes.set_xlabel('')\r\n",
        "axes.set_ylabel('')\r\n",
        "axes.tick_params(axis='x', labelsize=15)\r\n",
        "axes.tick_params(axis='y', labelsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-DEo-IzFJgb"
      },
      "source": [
        "import matplotlib \r\n",
        "matplotlib.rc('xtick', labelsize=20) \r\n",
        "matplotlib.rc('ytick', labelsize=20) \r\n",
        "\r\n",
        "\r\n",
        "df['Datetime'] = pd.to_datetime(df['Datetime'])\r\n",
        "\r\n",
        "df['month'] = df['Datetime'].dt.month\r\n",
        "\r\n",
        "df_groupby_month = df.groupby(by=[\"month\"], as_index=False).count()\r\n",
        "\r\n",
        "pie, ax = plt.subplots(figsize=[20,15])\r\n",
        "labels = ['Ekim', 'Kasım']\r\n",
        "plt.pie(x=df_groupby_month['Tweet Id'], autopct=\"%.1f%%\",  labels=labels, pctdistance=0.5, textprops={'fontsize': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO3T-28TH59Y"
      },
      "source": [
        "df['Datetime'] = pd.to_datetime(df['Datetime'])\r\n",
        "\r\n",
        "df['day'] = df['Datetime'].dt.day\r\n",
        "\r\n",
        "df_groupby_day = df.groupby(by=[\"day\"], as_index=False).count()\r\n",
        "df_groupby_day.sort_values(by='Tweet Id', ascending=False, inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "df_groupby_day[['day', 'Tweet Id']]\r\n",
        "\r\n",
        "days = df_groupby_day['day']\r\n",
        "\r\n",
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "plt.bar(x=df_groupby_day.sort_values(by='Tweet Id', ascending=False)['day'], height=df_groupby_day['Tweet Id'])\r\n",
        "\r\n",
        "axes.set_xlabel('')\r\n",
        "axes.set_ylabel('')\r\n",
        "axes.tick_params(axis='x', labelsize=15)\r\n",
        "axes.tick_params(axis='y', labelsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmiPxIFDHeFh"
      },
      "source": [
        "df['Datetime'] = pd.to_datetime(df['Datetime'])\r\n",
        "\r\n",
        "df['hour'] = df['Datetime'].dt.hour\r\n",
        "\r\n",
        "df_groupby_hour = df.groupby(by=[\"hour\"], as_index=False).count()\r\n",
        "df_groupby_hour\r\n",
        "\r\n",
        "fig, axes = plt.subplots()\r\n",
        "plt.tight_layout()\r\n",
        "\r\n",
        "labels = df_groupby_hour['hour']\r\n",
        "plt.bar(df_groupby_hour['hour'], df_groupby_hour['Tweet Id'])\r\n",
        "\r\n",
        "plt.xticks(df_groupby_hour['hour'], labels, rotation='vertical')\r\n",
        "\r\n",
        "plt.subplots_adjust(bottom=0.15)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atY7mDulUiuz"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw5ZcRrdX6Qw"
      },
      "source": [
        "df['hashtag_count2'] = df['Text'].apply(lambda x: len(re.findall('[\\s\\W]#(\\w+)', str(x))))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZEQL34Y0S1"
      },
      "source": [
        "df[df['hashtag_count2'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSNlU2DKXJ1j"
      },
      "source": [
        "df_grouped_by_hashtag_count = df.groupby(by=[\"hashtag_count\"], as_index=False).count()\r\n",
        "df_grouped_by_hashtag_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJh4GfShaW4n"
      },
      "source": [
        "df_grouped_by_url_count = df.groupby(by=[\"url_count\"], as_index=False).count()\r\n",
        "df_grouped_by_url_count\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(12,8))\r\n",
        "df_grouped_by_url_count.set_index(df_grouped_by_url_count['url_count'], inplace=True)\r\n",
        "\r\n",
        "plott = df_grouped_by_url_count.plot.pie(y='clean_text', autopct='%1.1f%%',figsize=(10, 10),  pctdistance=0.5, textprops={'fontsize': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGpuzQSebEz_"
      },
      "source": [
        "df_grouped_by_mention_count = df.groupby(by=[\"mention_count\"], as_index=False).count()\r\n",
        "df_grouped_by_mention_count\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(12,8))\r\n",
        "df_grouped_by_mention_count.set_index(df_grouped_by_mention_count['mention_count'], inplace=True)\r\n",
        "\r\n",
        "plott = df_grouped_by_mention_count.plot.pie(y='clean_text', figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrVX5i9RcV6g"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P_QOxlgcaw3"
      },
      "source": [
        "import seaborn as sns\r\n",
        "\r\n",
        "\r\n",
        "def listToString(s):  \r\n",
        "\r\n",
        "   mymy = re.findall('\\s([@][\\w_-]+)', s)\r\n",
        "   return ' '.join(mymy)\r\n",
        "\r\n",
        "    \r\n",
        "gg = df['Text'].apply(lambda x: listToString(x))\r\n",
        "\r\n",
        "hh = pd.Series(' '.join(gg).split()).value_counts()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77TbghR5ln2W"
      },
      "source": [
        "hh = pd.DataFrame(hh)\r\n",
        "\r\n",
        "mention_values = [hh.iloc[0].values[0], hh.iloc[1].values[0], hh.iloc[2].values[0], hh.iloc[3].values[0], hh.iloc[4].values[0],\r\n",
        "                  hh.iloc[5].values[0], hh.iloc[6].values[0], hh.iloc[7].values[0], hh.iloc[8].values[0], hh.iloc[9].values[0]]\r\n",
        "\r\n",
        "sns.barplot(y=hh.head(10).index, x=mention_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-5LUEmFzLXD"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}